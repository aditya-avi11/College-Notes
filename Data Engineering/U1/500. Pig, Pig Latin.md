
cd ~ : to go to home directory
(create any file here itself before running pig local)
pig -x local
r = LOAD 'load_eg.txt' USING PigStorage(',') AS (id:int, name:chararray, marks:int, subject:chararray);

r3 = FOREACH r GENERATE id, name, sub, marks;

----------------------------------------------------------------------------------------
2nd DAY:
--------------------
In home dir create a file student1.txt and enter records into it (srn,name,m1,m2,m3)
run pig local
r = LOAD 'student1.txt' USING PigStorage(',') AS (srn:int, name:chararray, m1:int, m2:int, m3:int);
NOW CREATE total COLUMN FIRST THEN CREATE average COLUMN USING total:
r = FOREACH r GENERATE srn, name, m1, m2, m3, m1+m2+m3 AS total;
##### r = FOREACH r GENERATE srn, name, m1, m2, m3, total, total/3.0F as avg;
---------------
Create a new pig file : (here instead of cmd line we can create a pig file and run the commands and manipulate the data)
-----------
nano student_data.pig
Enter following: 

--Load the File
r = LOAD 'student1.txt' USING PigStorage(',') AS (srn:int, name:chararray, m1:int, m2:int, m3:int);

--Find Total
r = FOREACH r GENERATE srn, name, m1, m2, m3, m1+m2+m3 AS total;

--Find Average
r = FOREACH r GENERATE srn, name, m1, m2, m3, total, total/3.0F as avg;

--Display r
--DUMP r;
STORE r INTO 'PigOut1' USING PigStorage(','); 
##### --this will create a new file in PigOut1 directory and store the content into it
--------------------------------------------------
Run the command : (This will run the pig file)
pig -x local student_data.pig

--------------------------------------------------
Also we can GROUP data based on some column :
r1 = GROUP r BY subject;
ILLUSTRATE r1; --this will show 1 sample of how the data is grouped
##### DUMP r1; --this will show entire grouped data
---------------------------------------------------------------------------------------

# 3rd Day:

r1 = FOREACH r GENERATE $0 as srn, $1 as name, $2 as marks, $3 as sub, $2+2 as newmarks;
rnull = FILTER r by $2 IS NULL;
rnotnull = FILTER r by $2 IS NOT NULL;
rnotnull1 = FILTER r BY $2 IS NOT NULL AND $3 IS NOT NULL;
rnotnull1 = FILTER r BY $2 IS NOT NULL OR $3 IS NOT NULL;
grouped_relation = GROUP original_relation BY field_name;


----------------------------------------------------------------------------------------

4th Day:

#### r1 = ORDER r BY $0 ASC, $1 DESC;
------

r = LOAD 'load_eg.txt' USING PigStorage(',') AS (id:int, name:chararray, marks:int, subject:chararray);
g = GROUP r BY subject;
a = FOREACH g GENERATE group AS sub, AVG(r.marks) AS avgmark;
a1 =  ORDER a BY avgmark;
f = FILTER r BY marks>90;
f1 = FILTER r BY marks>90 AND subject== 'Engineering';
f2 = FILTER r BY marks>90 AND subject== 'Engineering';
f2 = FILTER r BY marks IS NOT NULL;
f3 = FILTER r BY marks IS NULL;

#JOINS
ij = JOIN students BY sub, dept BY course;


----------------------------------------------------------------------------------

4th Day
----------------

Class 30-08-2024
Subject: Data Engineering

1. Left Join:
 leftJoin = JOIN students BY subject LEFT OUTER, dept BY course;

2. Right Join:
 rightJoin = JOIN students BY subject RIGHT OUTER, dept BY course;

Aggregate Functions:
( Can only be used on grouped data )
1. SUM
2. AVG
3. COUNT
4. MIN
5. MAX 
result= FOREACH grouped_data GENERATE max_marks AS MAX(marks);
****************************************

Type Conversion:
*If you try to typecast two uncompatible datatypes, it would return empty tuples(doesn't throw any errors)*
 r1 = FOREACH r GENERATE (float)marks as floatmarks;
*****************************************

Flatten Function:
*specially used to avoid nested tuples*
g1 = FOREACH g GENERATE group, FLATTEN(r.name);

*****************************************
MACROS:
* Similar to functions in other languages*
* $ sign is used only to identify the parameters and return value *

Example 1:
grunt> DEFINE my_macro(r) returns final_result {
>> g  = GROUP $r BY subject;
>> a = FOREACH g GENERATE group, AVG($r.marks);
>> $final_result = ORDER a BY $1;
>> };


Example 2:
grunt> DEFINE grace(r,val) RETURNS result
>>{
>> $result = FOREACH $ r GENERATE marks+$val AS newMarks;
>> }

*****************************************
UDF:
* recursive calls, if else, for else statements are not possible in pigLatin *
To overcome this drawback, UDF's are used:
UDFs are written in other high-level languages and used in Pig Environment

Piggy Bank: place where are UDFs are stored(registered)

Syntax:
REGISTER 'my_script' USING jython AS my_module;
* jython is a java defined function which converts your python code into java code. It allows your python code into piggy bank.*

---------------------------------------------------------------------------------------

DAY 5

students = LOAD 'load_eg.txt' USING PigStorage(',') AS (id:int, name:chararray, marks:int, subject:chararray);

udf.py contains a function to convert str to uppercase with a decorator
REGISTER 'udf.py' USING jython AS udf1;

r = FOREACH students GENERATE id, udf1.toUpper(name), marks, subject;
DUMP r;

---------------------------------------------------------------------------------------

SPARK Installation

brew install apache-spark
sudo apt update
sudo apt install python3-pip
pip install
source ~/.bashrc  (VVVVVVVVVERYYYYY IMPORTANT)

--
After this type : pyspark
then type following :
>>> rdd = sc.parallelize([1,2])
>>> rdd.collect()


--------------------------------------------------------------------------------------






