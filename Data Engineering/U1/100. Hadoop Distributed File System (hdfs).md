

Important :  [HDFS Architecture](https://www.spiceworks.com/tech/big-data/articles/hadoop-distributed-file-system-hdfs/) , [YouTube](https://www.youtube.com/watch?v=LOuAOZWJ9RA&list=PLxCzCOWd7aiHUUi6ZlansKbDw_cXut0El&pp=iAQB)

![[Pasted image 20240808191641.png]]
![[Pasted image 20240808155009.png]]
![[Pasted image 20240808160109.png]]
![[Pasted image 20240808160145.png]]

<hr><hr><hr>
==Summary of HDFS:== 
The Hadoop Distributed File System (HDFS) architecture is built on a master-slave model to store and manage large datasets across a distributed environment:

- **NameNode (Master)**: Manages the file system's metadata, including file structure and block locations. It coordinates access to files and oversees data replication across the cluster.
    
- **DataNodes (Slaves)**: Store the actual data blocks and handle read/write requests from clients. They also report the blocks they store to the NameNode and replicate blocks as instructed.
    
- **Secondary NameNode**: Performs housekeeping tasks, like merging edit logs with the file system image to help the NameNode manage metadata efficiently.
    
- **HDFS Client**: Interacts with the NameNode to access file metadata and with DataNodes to read or write data directly.
    
**Blocks** are the basic storage units, replicated across multiple DataNodes to ensure fault tolerance. The system is optimized for scalability, high throughput, and data reliability, with features like rack awareness and high availability.

The Hadoop Distributed File System (HDFS) is a core component of the Apache Hadoop ecosystem, ==designed to store large datasets reliably and to stream those datasets at high bandwidth to user applications==. The architecture of HDFS is built around a master-slave topology and is designed for ==scalability, fault tolerance, and high throughput==. Here's an overview of the HDFS architecture:
<hr><hr><hr>


### 1. **NameNode (Master)**

- **Role**: The NameNode is the centerpiece of HDFS architecture and acts as the ==master server==. It manages the file system's namespace and controls access to files by clients.
- **Responsibilities**:
    - **Namespace Management**: Keeps track of the structure of the file system, including directories and files.
    - **Block Management**: Maintains the mapping of files to blocks and the DataNodes on which these blocks are stored.
    - ==**Metadata== Storage**: Stores metadata, such as ==file permissions, ownership, and file-to-block mapping==s, in memory for fast access.
    - **Cluster Coordination**: Coordinates replication of data blocks, handling of DataNode failures, and ensuring data availability and consistency.

### 2. **DataNodes (Slaves)**

- **Role**: DataNodes are the worker nodes that store and retrieve data blocks on behalf of clients or the NameNode.
- **Responsibilities**:
    - **Block Storage**: Store the actual data blocks that make up the files in HDFS.
    - **Block Reporting**: Periodically report the list of blocks they are storing to the NameNode.
    - **Block Replication**: Manage replication of data blocks based on the replication factor specified by the NameNode.
    - **Data Retrieval**: Handle read and write requests from clients, streaming data directly between the client and the DataNode.

### 3. **Secondary NameNode**

- **Role**: The Secondary NameNode is not a backup for the NameNode, despite the misleading name. Instead, it performs housekeeping functions to help the NameNode.
- **Responsibilities**:
    - **Checkpointing**: Periodically merges the edit logs and the file system image from the NameNode to create a new checkpoint. This process reduces the load on the NameNode by keeping its edit log from growing too large.
    - **Assistance with Recovery**: In case of NameNode failure, the checkpoints can be used to restart the NameNode, though it is not a full replacement.

### 4. **HDFS Client**

- **Role**: The HDFS client is the interface for users to interact with HDFS. It provides the APIs necessary to perform operations such as reading and writing data.
- **Responsibilities**:
    - **File Operations**: Handles file operations like opening, reading, writing, renaming, and deleting files.
    - **Block Management**: Communicates with the NameNode to determine where data blocks are stored, and interacts directly with DataNodes to read/write data.

### 5. ==**HDFS Blocks**==

- **Concept**: Files in HDFS are divided into large blocks, typically 128 MB or 256 MB in size (configurable). These blocks are the basic units of storage and replication in HDFS.
- **Replication**: Each block is replicated across multiple DataNodes to ensure reliability and availability. The default replication factor is 3, meaning each block is stored on three different DataNodes.
- **Fault Tolerance**: If a DataNode fails, the NameNode detects the failure and replicates the blocks from the failed DataNode to other available DataNodes to maintain the specified replication factor.
- (If a DataNode fails, the NameNode notices the missing heartbeats from that DataNode and identifies it as down. To ensure data remains safe and available, the NameNode instructs other healthy DataNodes to create new copies (replicas) of the blocks that were stored on the failed DataNode. This process keeps the data replication at the required level, ensuring that the data is still accessible even after the failure.)

### 6. **High Availability**

- **Feature**: HDFS can be configured in a high-availability mode, where there are multiple NameNodes, typically an active and a standby. This setup ensures that in case of failure of the active NameNode, the standby can take over, minimizing downtime.

### 7. **Rack Awareness**

- **Feature**: HDFS is aware of the physical location of DataNodes within the network, usually grouped by racks. This awareness allows the NameNode to optimize block placement for fault tolerance and network efficiency, by ensuring that replicas are placed on different racks.

### 8. **Data Replication and Consistency**

- **Replication Strategy**: HDFS uses a rack-aware replication strategy to ensure that data is not lost even if a whole rack fails. The default strategy places one replica on the local rack, another on a different rack, and the third one on a different node in the same second rack.
- **Consistency**: HDFS guarantees write-once-read-many (WORM) semantics, meaning files are immutable once written and can only be appended, not modified.

### 9. **Scalability and Performance**

- **Scalability**: HDFS is designed to scale to thousands of nodes and petabytes of data. It can accommodate more DataNodes as the cluster grows without significant reconfiguration.
- **Performance**: HDFS is optimized for high throughput rather than low latency, making it suitable for batch processing of large datasets.

### Summary:

HDFS is a distributed file system designed to store large amounts of data reliably and to provide high-throughput access to this data. Its architecture is highly fault-tolerant, with mechanisms in place to handle node failures and ensure data availability. The division of data into blocks, managed by the NameNode and stored on DataNodes, allows HDFS to scale efficiently across many nodes while providing consistent and reliable storage.


<hr><hr><hr>

# Read & Write Operations on HDFS

The processes of reading and writing data in Hadoop Distributed File System (HDFS) involve interaction between the client, NameNode, and DataNodes. Understanding these processes is key to comprehending how HDFS manages data efficiently and reliably.

### 1. **Write Operation in HDFS**

When a client writes data to HDFS, the data is broken down into blocks and replicated across multiple DataNodes to ensure fault tolerance. Here's a step-by-step breakdown of the write operation:

#### **Step 1: Client Request**

- The client initiates a file creation request by contacting the NameNode.
- The NameNode checks whether the file already exists and whether the client has the required permissions. If everything is fine, the NameNode allows the creation of the file.

#### **Step 2: Block Allocation**

- The NameNode doesn't store the actual data but keeps metadata about the file, such as the block locations and the DataNodes that will store each block.
- The NameNode assigns a list of DataNodes where each block of the file should be stored. This is based on the replication factor (typically 3).

#### **Step 3: Data Streaming to DataNodes**

- The client begins writing data to the first DataNode in the list provided by the NameNode.
- Once the first DataNode receives the data, it starts streaming it to the second DataNode, which then streams it to the third DataNode (if the replication factor is 3). This pipeline ensures that data is replicated across multiple DataNodes.

#### **Step 4: Block Report and Acknowledgment**

- After the data block is written and replicated across all the assigned DataNodes, each DataNode sends an acknowledgment to the client.
- Once all acknowledgments are received, the client proceeds to write the next block.

#### **Step 5: Metadata Update**

- After all blocks are written and acknowledged, the client informs the NameNode that the file has been completely written.
- The NameNode updates the file system's metadata to reflect the new file and its associated blocks.

#### **Key Points:**

- **Fault Tolerance**: HDFS ensures data reliability by replicating each block across multiple DataNodes.
- **Pipeline Replication**: The write process follows a pipeline fashion, where data is streamed from one DataNode to another.
- **High Throughput**: The design is optimized for high throughput rather than low latency, making it suitable for large file writes.

### 2. **Read Operation in HDFS**

When a client wants to read data from HDFS, the process involves locating the data blocks on the DataNodes and streaming them back to the client. Here’s how the read operation works:

#### **Step 1: Client Request**

- The client contacts the NameNode to request reading a file.
- The NameNode responds with the metadata, including the locations of the blocks that make up the file, and the DataNodes where these blocks are stored.

#### **Step 2: Block Retrieval**

- The client directly contacts the nearest DataNode (based on network topology) that holds a replica of the first block.
- The DataNode streams the block data back to the client.

#### **Step 3: Pipeline Reading**

- After reading the first block, the client continues to the next block, contacting the appropriate DataNode as indicated by the metadata.
- This process continues until the client has read all blocks of the file.

#### **Step 4: Handling Failures**

- If a DataNode fails during the read process, the client can request the block from another DataNode that holds a replica.
- The NameNode can also direct the client to an alternative DataNode if the client reports a failure.

#### **Key Points:**

- **Data Locality**: HDFS tries to optimize the read process by allowing the client to fetch data from the nearest DataNode, reducing network congestion.
- **Fault Tolerance**: The replication of data blocks ensures that even if one DataNode is down, the client can still access the data from another DataNode.
- **Read Consistency**: HDFS provides a consistent view of the file system to the client, ensuring that only completed writes are visible.

### **Summary**

- **Write Operation**: Involves the client requesting to create a file, block allocation by the NameNode, data streaming and replication to multiple DataNodes, and updating metadata upon successful write completion.
- **Read Operation**: Involves the client requesting to read a file, retrieving block locations from the NameNode, and streaming data directly from DataNodes, with automatic failover in case of DataNode failures.

These processes highlight HDFS's design for high availability, fault tolerance, and scalability, which are crucial for managing large-scale data processing tasks in a distributed environment.


<hr><hr><hr><hr>

Here's the working flow of HDFS in a pointwise manner:

### 1. **File Creation (Write Operation)**

- **Client Request**: Client requests the NameNode to create a new file.
- **Permission Check**: NameNode checks if the file exists and if the client has necessary permissions.
- **Block Allocation**: NameNode allocates blocks and assigns DataNodes to store these blocks.
- **Data Streaming**: Client starts streaming data to the first DataNode, which then forwards it to other DataNodes in a pipeline fashion based on the replication factor.
- **Acknowledgment**: DataNodes send acknowledgments back to the client after successfully storing each block.
- **Metadata Update**: After all blocks are written, the client informs the NameNode, which then updates the file system metadata.

### 2. **File Reading (Read Operation)**

- **Client Request**: Client requests the NameNode for reading a file.
- **Metadata Retrieval**: NameNode provides the client with the metadata, including block locations and associated DataNodes.
- **Data Retrieval**: Client directly contacts the nearest DataNode holding the required block and retrieves the data.
- **Pipeline Reading**: Client reads data sequentially by contacting the appropriate DataNodes for each block.
- **Failure Handling**: If a DataNode fails, the client retrieves the block from another DataNode that holds a replica.

### 3. **Data Integrity and Fault Tolerance**

- **Block Replication**: Each data block is replicated across multiple DataNodes (default is 3 replicas) to ensure fault tolerance.
- **Heartbeat and Block Report**: DataNodes periodically send heartbeats and block reports to the NameNode to confirm their status and block storage.
- **Failure Detection**: If a DataNode fails to send a heartbeat, the NameNode marks it as failed and initiates block replication to other healthy DataNodes.

### 4. **High Availability**

- **Secondary NameNode**: Periodically merges the NameNode’s edit logs with the file system image to create checkpoints, aiding in recovery.
- **Active/Standby NameNodes**: In high-availability setups, a standby NameNode can take over if the active NameNode fails, ensuring continuous operation.

### 5. **Rack Awareness**

- **Rack-Based Block Placement**: The NameNode uses a rack-aware algorithm to place replicas across different racks, ensuring data remains available even if an entire rack fails.

### 6. **Scalability and Performance**

- **Horizontal Scalability**: HDFS can easily scale by adding more DataNodes to the cluster without significant reconfiguration.
- **High Throughput**: Optimized for batch processing and large file operations, prioritizing throughput over latency.