
### **YARN (Yet Another Resource Negotiator)**

- **Resource Management**: YARN is Hadoop's cluster resource management layer, responsible for allocating system resources like CPU and memory to various applications running on the Hadoop cluster.
- **Components**:
    - **ResourceManager**: Central authority that manages resources and schedules tasks across the cluster.
    - **NodeManager**: Runs on each cluster node, monitors resource usage, and manages individual tasks.
    - **ApplicationMaster**: Manages the execution of a single application by negotiating resources and monitoring progress.
- **Scalability**: YARN allows Hadoop to support multiple applications simultaneously, improving cluster utilization and scalability.
- **Flexibility**: Supports different processing frameworks (e.g., MapReduce, Spark) running on the same Hadoop cluster.

### **Hive**

- **Data Warehousing**: Hive is a data warehousing tool on top of Hadoop, enabling users to perform SQL-like queries on large datasets stored in HDFS.
- **HiveQL**: Uses a query language similar to SQL, making it accessible to users familiar with traditional databases.
- **Batch Processing**: Converts HiveQL queries into MapReduce, Tez, or Spark jobs, allowing batch processing of data.
- **Schema on Read**: Supports schema-on-read, meaning data can be loaded without needing to define a schema upfront.
- **Integration**: Works well with other Hadoop ecosystem tools like Pig, HBase, and HDFS for efficient data processing and storage.
- ![[Pasted image 20240808215827.png]]

### **Apache Pig**

- **Data Processing Tool**: Pig is a high-level platform for processing large data sets in Hadoop, designed for analyzing data flows.
- **Pig Latin**: The core language used in Pig, a scripting language that allows users to write data analysis programs. It's simpler than Java and abstracts the complexity of writing MapReduce programs.
- **Data Transformation**: Pig is mainly used for ETL (Extract, Transform, Load) tasks, including filtering, grouping, and joining data.
- **Execution Modes**:
    - **Local Mode**: Runs on a single machine, used for testing and development.
    - **MapReduce Mode**: Runs on a Hadoop cluster, translating Pig Latin scripts into MapReduce jobs for distributed processing.
- **Schema on Read**: Similar to Hive, Pig supports schema-on-read, meaning it doesnâ€™t require predefined schemas, making it flexible for handling semi-structured data.
- **Extensibility**: Allows users to write custom functions (UDFs) in Java, Python, and other languages to perform specific tasks within Pig scripts.
- **Usage**: Popular for tasks like data cleaning, log analysis, and data transformation in Hadoop.