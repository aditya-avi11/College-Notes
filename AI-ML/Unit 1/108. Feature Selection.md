
### Feature Selection in Machine Learning

Feature selection involves choosing the most important features from your dataset to improve model performance and reduce overfitting. Hereâ€™s how you can select significant features using some common techniques:

#### 1. **SelectKBest**

**SelectKBest** is a feature selection method that selects the top k features ***based on a statistical test***.

- **Parameters**:
    - `X`: Feature matrix (input features).
    - `y`: Target vector (output labels).
    - `k`: Number of top features to select.

## For Classification Problems:

- ==**Chi-Square Test== (`chi2`)**: Measures the dependence between features and the target variable.
    
    **Example**:
   ```python
	    from sklearn.feature_selection import SelectKBest, chi2
		from sklearn.datasets import load_iris
		import pandas as pd
		
		# Load dataset
		data = load_iris()
		X = data.data
		y = data.target
		
		# Apply SelectKBest with Chi2
		selector = SelectKBest(score_func=chi2, k=2)
		X_new = selector.fit_transform(X, y)
		
		print("Original shape:", X.shape)
		print("New shape:", X_new.shape)
```


## For Regression Problems:

- ==**F-Regression== (`f_regression`)**: Measures the linear relationship between each feature and the target variable.
    
    **Example**:
	 ```python
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.datasets import load_boston
import pandas as pd
	
Load dataset
data = load_boston()
X = data.data
y = data.target
	
Apply SelectKBest with F-regression
selector = SelectKBest(score_func=f_regression, k=2)
X_new = selector.fit_transform(X, y)
	
print("Original shape:", X.shape)
print("New shape:", X_new.shape)
``` 

![[Pasted image 20240806231418.png]]
![[Pasted image 20240806231432.png]]



# Train Test Split

![[Pasted image 20240806231545.png]]

![[Pasted image 20240806231610.png]]


.

